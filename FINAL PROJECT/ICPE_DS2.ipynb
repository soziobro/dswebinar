{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "ICPE_DS2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn0LUzTkL8Cm"
      },
      "source": [
        "# Image Classification with Keras\n",
        "(30 points)\n",
        "### **Dataset**\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The 10 classes are:\n",
        "1. airplane\t\t\t\t\t\t\t\t\t\t\n",
        "2. automobile\t\t\t\t\t\t\t\t\t\t\n",
        "3. bird\t\t\t\t\t\t\t\t\t\t\n",
        "4. cat\t\t\t\t\t\t\t\t\t\t\n",
        "5. deer\t\t\t\t\t\t\t\t\t\t\n",
        "6. dog\t\t\t\t\t\t\t\t\t\t\n",
        "7. frog\t\t\t\t\t\t\t\t\t\t\n",
        "8. horse\t\t\t\t\t\t\t\t\t\t\n",
        "9. ship\t\t\t\t\t\t\t\t\t\t\n",
        "10. truck\n",
        "\n",
        "### **Problem**\n",
        "1. create two deep neural network models: one with one Dense layer that contains 512 neurons and the other one with two Dense layers that contain 256 neurons in each layer.\n",
        "\n",
        "2. compiler both models by setting the optimizer to **adam** (adaptive moment estimation) and loss function to **\"sparse_categorical_crossentropy\"**. \n",
        "\n",
        "3. train both models for **20 epochs** and output the **validation error** for both models.\n",
        "\n",
        "3. compare the validation error of your models against that of the convolution neural network (CNN) model provided below and explain why CNN model is doing better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x_VyFh1S-VB"
      },
      "source": [
        "## Load and process the dataset for training\n",
        "**Please don't change this section!** \n",
        "\n",
        "You can use `(X_train, y_train) and (X_test, y_test)` for training and testing in your code respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r84SykyrL8Cm"
      },
      "source": [
        "%load_ext tensorboard\n",
        "from tensorflow.keras import utils, callbacks, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten, Conv2D, MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmxng7RWL8Cm"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXpAfP_dL8Cn"
      },
      "source": [
        "# show the first image in the data set\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-upAz4bJghJ"
      },
      "source": [
        "# show the first 15 images in the data set.\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "for i in range(20):\n",
        "    plt.subplot(4,5,i+1)\n",
        "    #plt.tight_layout()\n",
        "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "    plt.title(class_names[y_train[i][0]])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xvt0VSXLOvW"
      },
      "source": [
        "# Normalize the train dataset\n",
        "X_train = utils.normalize(X_train, axis=1)\n",
        "# Normalize the test dataset\n",
        "X_test = utils.normalize(X_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd1hnWCeS0WC"
      },
      "source": [
        "## Build, compile, and train the model object\n",
        "You can start creating, compiling, and training your models here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jZp45uZkyM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T8dICtpv-tQ"
      },
      "source": [
        "## Compare against Convolution Neural Network (CNN) Model\n",
        "**Please don't change this section!** \n",
        "\n",
        "You just need to run the following to create and train a convolution neural network and compare the validation error to those from your models and explain why CNN is better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlBkwmPOWjAL"
      },
      "source": [
        "!rm -rf logs/model_cnn\n",
        "#Build the model object\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(64, activation='relu'))\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_cnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "# This is needed for loading Tensorboard.\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"logs/model_cnn\", histogram_freq=1)\n",
        "model_cnn.fit(x=X_train, y=y_train, epochs=20, \n",
        "      validation_data=(X_test, y_test),\n",
        "      callbacks=[tensorboard_callback]) # Start training process"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}